{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emmanuel Decena - ME EE**\n",
    "Deep Learning Assignment\n",
    "\n",
    "Build a classifier on CIFAR10 dataset using\n",
    "- 3-layer MLP\n",
    "- 3-layer +1 CNN\n",
    "\n",
    "Compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using 3-Layer MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size * 3\n",
    "\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size]) \n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 256\n",
    "n_units = 256\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3-layer-MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 855,050\n",
      "Trainable params: 855,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model is a 3-layer MLP\n",
    "model = Sequential(name='3-layer-MLP')\n",
    "model.add(Dense(n_units, input_dim=input_size, activation='relu', name='input_layer'))\n",
    "model.add(Dense(n_units, activation='relu', name='hidden_layer'))\n",
    "model.add(Dense(num_labels, activation='softmax', name='output_layer'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 2.0616 - accuracy: 0.2639 - val_loss: 1.9765 - val_accuracy: 0.2836\n",
      "Epoch 2/30\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 1.8945 - accuracy: 0.3335 - val_loss: 1.8955 - val_accuracy: 0.3204\n",
      "Epoch 3/30\n",
      "196/196 [==============================] - 12s 63ms/step - loss: 1.8316 - accuracy: 0.3606 - val_loss: 1.8244 - val_accuracy: 0.3632\n",
      "Epoch 4/30\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.7908 - accuracy: 0.3740 - val_loss: 1.7985 - val_accuracy: 0.3627\n",
      "Epoch 5/30\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.7581 - accuracy: 0.3860 - val_loss: 1.8508 - val_accuracy: 0.3419\n",
      "Epoch 6/30\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 1.7315 - accuracy: 0.3947 - val_loss: 1.7339 - val_accuracy: 0.3847\n",
      "Epoch 7/30\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.7064 - accuracy: 0.4041 - val_loss: 1.7074 - val_accuracy: 0.3992\n",
      "Epoch 8/30\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.6833 - accuracy: 0.4114 - val_loss: 1.6840 - val_accuracy: 0.4067\n",
      "Epoch 9/30\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6661 - accuracy: 0.4189 - val_loss: 1.6962 - val_accuracy: 0.4078\n",
      "Epoch 10/30\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6456 - accuracy: 0.4236 - val_loss: 1.6897 - val_accuracy: 0.3998\n",
      "Epoch 11/30\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 1.6291 - accuracy: 0.4310 - val_loss: 1.6424 - val_accuracy: 0.4300\n",
      "Epoch 12/30\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.6150 - accuracy: 0.4331 - val_loss: 1.6348 - val_accuracy: 0.4302\n",
      "Epoch 13/30\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5973 - accuracy: 0.4418 - val_loss: 1.6035 - val_accuracy: 0.4371\n",
      "Epoch 14/30\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.5860 - accuracy: 0.4463 - val_loss: 1.6081 - val_accuracy: 0.4367\n",
      "Epoch 15/30\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5747 - accuracy: 0.4485 - val_loss: 1.6095 - val_accuracy: 0.4362\n",
      "Epoch 16/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.5587 - accuracy: 0.4543 - val_loss: 1.6559 - val_accuracy: 0.4004\n",
      "Epoch 17/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.5510 - accuracy: 0.4575 - val_loss: 1.6088 - val_accuracy: 0.4381\n",
      "Epoch 18/30\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 1.5408 - accuracy: 0.4606 - val_loss: 1.5875 - val_accuracy: 0.4375\n",
      "Epoch 19/30\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 1.5299 - accuracy: 0.4639 - val_loss: 1.6150 - val_accuracy: 0.4299\n",
      "Epoch 20/30\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 1.5206 - accuracy: 0.4691 - val_loss: 1.5490 - val_accuracy: 0.4546\n",
      "Epoch 21/30\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.5089 - accuracy: 0.4736 - val_loss: 1.5478 - val_accuracy: 0.4554\n",
      "Epoch 22/30\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.4979 - accuracy: 0.4762 - val_loss: 1.5404 - val_accuracy: 0.4539\n",
      "Epoch 23/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.4923 - accuracy: 0.4778 - val_loss: 1.5441 - val_accuracy: 0.4555\n",
      "Epoch 24/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.4822 - accuracy: 0.4818 - val_loss: 1.6635 - val_accuracy: 0.4131\n",
      "Epoch 25/30\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.4782 - accuracy: 0.4818 - val_loss: 1.5306 - val_accuracy: 0.4576\n",
      "Epoch 26/30\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 1.4699 - accuracy: 0.4861 - val_loss: 1.5264 - val_accuracy: 0.4581\n",
      "Epoch 27/30\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.4590 - accuracy: 0.4889 - val_loss: 1.5131 - val_accuracy: 0.4646\n",
      "Epoch 28/30\n",
      "196/196 [==============================] - 6s 33ms/step - loss: 1.4509 - accuracy: 0.4940 - val_loss: 1.5300 - val_accuracy: 0.4601\n",
      "Epoch 29/30\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 1.4435 - accuracy: 0.4956 - val_loss: 1.5547 - val_accuracy: 0.4498\n",
      "Epoch 30/30\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.4364 - accuracy: 0.4972 - val_loss: 1.4716 - val_accuracy: 0.4837\n",
      "\n",
      "Test accuracy: 48.4%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=False)\n",
    "\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Using 3-Layer CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "image_size = x_train.shape[1]\n",
    "# resize and normalize\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "input_shape = (image_size, image_size, 3)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "pool_size = 3\n",
    "filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Conv2D)         (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "hidden_layer (MaxPooling2D)  (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Flatten)      (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                32010     \n",
      "=================================================================\n",
      "Total params: 32,906\n",
      "Trainable params: 32,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size, \n",
    "                 activation='relu', \n",
    "                 kernel_initializer='he_uniform', \n",
    "                 padding='same', \n",
    "                 input_shape=input_shape,\n",
    "                 name='input_layer'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size,name='hidden_layer'))\n",
    "model.add(Flatten(name='hidden_layer2'))\n",
    "model.add(Dense(10, activation='softmax',name='output_layer'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 [==============================] - 22s 110ms/step - loss: 2.0965 - accuracy: 0.2381\n",
      "Epoch 2/30\n",
      "196/196 [==============================] - 24s 120ms/step - loss: 1.8773 - accuracy: 0.3403\n",
      "Epoch 3/30\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 1.7872 - accuracy: 0.3816\n",
      "Epoch 4/30\n",
      "196/196 [==============================] - 26s 131ms/step - loss: 1.7237 - accuracy: 0.4033\n",
      "Epoch 5/30\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 1.6778 - accuracy: 0.4217\n",
      "Epoch 6/30\n",
      "196/196 [==============================] - 27s 135ms/step - loss: 1.6385 - accuracy: 0.4347\n",
      "Epoch 7/30\n",
      "196/196 [==============================] - 32s 166ms/step - loss: 1.6036 - accuracy: 0.4460\n",
      "Epoch 8/30\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 1.5734 - accuracy: 0.4577\n",
      "Epoch 9/30\n",
      "196/196 [==============================] - 23s 117ms/step - loss: 1.5463 - accuracy: 0.4663\n",
      "Epoch 10/30\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 1.5225 - accuracy: 0.4776\n",
      "Epoch 11/30\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 1.5023 - accuracy: 0.4837\n",
      "Epoch 12/30\n",
      "196/196 [==============================] - 19s 99ms/step - loss: 1.4821 - accuracy: 0.4907\n",
      "Epoch 13/30\n",
      "196/196 [==============================] - 44s 227ms/step - loss: 1.4641 - accuracy: 0.4965\n",
      "Epoch 14/30\n",
      "196/196 [==============================] - 27s 137ms/step - loss: 1.4449 - accuracy: 0.5062\n",
      "Epoch 15/30\n",
      "196/196 [==============================] - 38s 194ms/step - loss: 1.4296 - accuracy: 0.5123\n",
      "Epoch 16/30\n",
      "196/196 [==============================] - 34s 173ms/step - loss: 1.4143 - accuracy: 0.5176\n",
      "Epoch 17/30\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 1.3992 - accuracy: 0.5225\n",
      "Epoch 18/30\n",
      "196/196 [==============================] - 34s 174ms/step - loss: 1.3845 - accuracy: 0.5288\n",
      "Epoch 19/30\n",
      "196/196 [==============================] - 26s 131ms/step - loss: 1.3711 - accuracy: 0.5327\n",
      "Epoch 20/30\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 1.3591 - accuracy: 0.5372\n",
      "Epoch 21/30\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 1.3457 - accuracy: 0.5409\n",
      "Epoch 22/30\n",
      "196/196 [==============================] - 21s 107ms/step - loss: 1.3346 - accuracy: 0.5468\n",
      "Epoch 23/30\n",
      "196/196 [==============================] - 21s 106ms/step - loss: 1.3232 - accuracy: 0.5507\n",
      "Epoch 24/30\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 1.3130 - accuracy: 0.5537\n",
      "Epoch 25/30\n",
      "196/196 [==============================] - 21s 106ms/step - loss: 1.3026 - accuracy: 0.5557\n",
      "Epoch 26/30\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 1.2925 - accuracy: 0.5607\n",
      "Epoch 27/30\n",
      "196/196 [==============================] - 20s 100ms/step - loss: 1.2843 - accuracy: 0.5614\n",
      "Epoch 28/30\n",
      "196/196 [==============================] - 19s 99ms/step - loss: 1.2734 - accuracy: 0.5678\n",
      "Epoch 29/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.2658 - accuracy: 0.5700\n",
      "Epoch 30/30\n",
      "196/196 [==============================] - 25s 125ms/step - loss: 1.2574 - accuracy: 0.5739\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 1.2924 - accuracy: 0.5509\n",
      "\n",
      "Test accuracy: 55.1%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **3. Performance**\n",
    "\n",
    "The MLP model was outperformed by the CNN model using the same epochs and layers. \n",
    "The MLP's accuracy of ~48% was lower compared to the CNN accuracy of ~55%.\n",
    "The MLP also used more parameters at 855,050 compared to the CNN using only 32,906. Thus, the CNN model was more parameter efficient and has higher accuracy. Using the CNN model is more suitable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
