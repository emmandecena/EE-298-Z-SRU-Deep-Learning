{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emmanuel Decena - ME EE**\n",
    "Deep Learning Assignment\n",
    "\n",
    "Build a classifier on CIFAR10 dataset using\n",
    "- 3-layer MLP\n",
    "- 3-layer CNN\n",
    "\n",
    "Compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using 3-Layer MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size * 3\n",
    "\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size]) \n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 256\n",
    "n_units = 256\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3-layer-MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 855,050\n",
      "Trainable params: 855,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model is a 3-layer MLP\n",
    "model = Sequential(name='3-layer-MLP')\n",
    "model.add(Dense(n_units, input_dim=input_size, activation='relu', name='input_layer'))\n",
    "model.add(Dense(n_units, activation='relu', name='hidden_layer'))\n",
    "model.add(Dense(num_labels, activation='softmax', name='output_layer'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 2.0759 - accuracy: 0.2589 - val_loss: 1.9620 - val_accuracy: 0.2861\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 1.8968 - accuracy: 0.3345 - val_loss: 1.8576 - val_accuracy: 0.3447\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.8329 - accuracy: 0.3574 - val_loss: 1.8351 - val_accuracy: 0.3565\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 1.7909 - accuracy: 0.3745 - val_loss: 1.7859 - val_accuracy: 0.3715\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.7568 - accuracy: 0.3865 - val_loss: 1.7802 - val_accuracy: 0.3757\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.7273 - accuracy: 0.3949 - val_loss: 1.7253 - val_accuracy: 0.3979\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 1.7048 - accuracy: 0.4029 - val_loss: 1.7047 - val_accuracy: 0.4037\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 1.6818 - accuracy: 0.4127 - val_loss: 1.6889 - val_accuracy: 0.4110\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 1.6607 - accuracy: 0.4207 - val_loss: 1.6735 - val_accuracy: 0.4133\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.6426 - accuracy: 0.4276 - val_loss: 1.7554 - val_accuracy: 0.3740\n",
      "\n",
      "Test accuracy: 37.4%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=False)\n",
    "\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Using 3-Layer CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "image_size = x_train.shape[1]\n",
    "# resize and normalize\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "input_shape = (image_size, image_size, 3)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "pool_size = 3\n",
    "filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Conv2D)         (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "hidden_layer (MaxPooling2D)  (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                32010     \n",
      "=================================================================\n",
      "Total params: 32,906\n",
      "Trainable params: 32,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size, \n",
    "                 activation='relu', \n",
    "                 kernel_initializer='he_uniform', \n",
    "                 padding='same', \n",
    "                 input_shape=input_shape,\n",
    "                 name='input_layer'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size,name='hidden_layer'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax',name='output_layer'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 21s 106ms/step - loss: 1.0762 - accuracy: 0.6346\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 18s 93ms/step - loss: 1.0605 - accuracy: 0.6400\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 1.0471 - accuracy: 0.6424\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 22s 115ms/step - loss: 1.0493 - accuracy: 0.6435\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 21s 109ms/step - loss: 1.0413 - accuracy: 0.6470\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 22s 112ms/step - loss: 1.0417 - accuracy: 0.6441\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 1.0336 - accuracy: 0.6497\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 20s 102ms/step - loss: 1.0328 - accuracy: 0.6493\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 20s 102ms/step - loss: 1.0344 - accuracy: 0.6479\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 1.0283 - accuracy: 0.6512\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 1.0940 - accuracy: 0.6284\n",
      "\n",
      "Test accuracy: 62.8%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Performance**\n",
    "\n",
    "The MLP model was outperformed by the CNN model using the same epochs and layers. \n",
    "The MLP's accuracy of ~30% was lower compared to the CNN accuracy of ~50%.\n",
    "The MLP also used approximately ten times as much parameters at 855,050 compared to the CNN at 82,346.\n",
    "The CNN model was more parameter efficient and has higher accuracy and thus is more suitable to use for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
