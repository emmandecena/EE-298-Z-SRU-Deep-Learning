{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emmanuel Decena - ME EE**\n",
    "Deep Learning Assignment\n",
    "\n",
    "Build a classifier on CIFAR10 dataset using\n",
    "- 3-layer MLP\n",
    "- 3-layer +1 CNN\n",
    "\n",
    "Compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Using 3-Layer MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size * 3\n",
    "\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size]) \n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 256\n",
    "n_units = 256\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3-layer-MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 855,050\n",
      "Trainable params: 855,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model is a 3-layer MLP\n",
    "model = Sequential(name='3-layer-MLP')\n",
    "model.add(Dense(n_units, input_dim=input_size, activation='relu', name='input_layer'))\n",
    "model.add(Dense(n_units, activation='relu', name='hidden_layer'))\n",
    "model.add(Dense(num_labels, activation='softmax', name='output_layer'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 2.0753 - accuracy: 0.2612 - val_loss: 1.9566 - val_accuracy: 0.2949\n",
      "Epoch 2/30\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 1.8960 - accuracy: 0.3383 - val_loss: 1.8612 - val_accuracy: 0.3522\n",
      "Epoch 3/30\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 1.8234 - accuracy: 0.3622 - val_loss: 1.8129 - val_accuracy: 0.3650\n",
      "Epoch 4/30\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 1.7792 - accuracy: 0.3805 - val_loss: 1.7718 - val_accuracy: 0.3813\n",
      "Epoch 5/30\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.7449 - accuracy: 0.3895 - val_loss: 1.7375 - val_accuracy: 0.3868\n",
      "Epoch 6/30\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.7151 - accuracy: 0.4022 - val_loss: 1.7271 - val_accuracy: 0.4017\n",
      "Epoch 7/30\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.6901 - accuracy: 0.4107 - val_loss: 1.6944 - val_accuracy: 0.4053\n",
      "Epoch 8/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.6700 - accuracy: 0.4161 - val_loss: 1.6918 - val_accuracy: 0.3961\n",
      "Epoch 9/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.6497 - accuracy: 0.4245 - val_loss: 1.6437 - val_accuracy: 0.4251\n",
      "Epoch 10/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.6320 - accuracy: 0.4300 - val_loss: 1.6432 - val_accuracy: 0.4252\n",
      "Epoch 11/30\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.6165 - accuracy: 0.4368 - val_loss: 1.6580 - val_accuracy: 0.4178\n",
      "Epoch 12/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.6014 - accuracy: 0.4392 - val_loss: 1.6296 - val_accuracy: 0.4242\n",
      "Epoch 13/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.5874 - accuracy: 0.4445 - val_loss: 1.6137 - val_accuracy: 0.4292\n",
      "Epoch 14/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.5733 - accuracy: 0.4497 - val_loss: 1.6459 - val_accuracy: 0.4228\n",
      "Epoch 15/30\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.5638 - accuracy: 0.4537 - val_loss: 1.5699 - val_accuracy: 0.4458\n",
      "Epoch 16/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.5507 - accuracy: 0.4588 - val_loss: 1.5765 - val_accuracy: 0.4438\n",
      "Epoch 17/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.5406 - accuracy: 0.4622 - val_loss: 1.6435 - val_accuracy: 0.4227\n",
      "Epoch 18/30\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.5300 - accuracy: 0.4674 - val_loss: 1.6258 - val_accuracy: 0.4286\n",
      "Epoch 19/30\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.5204 - accuracy: 0.4683 - val_loss: 1.5447 - val_accuracy: 0.4521\n",
      "Epoch 20/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.5109 - accuracy: 0.4734 - val_loss: 1.5663 - val_accuracy: 0.4447\n",
      "Epoch 21/30\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.5036 - accuracy: 0.4739 - val_loss: 1.5437 - val_accuracy: 0.4488\n",
      "Epoch 22/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.4929 - accuracy: 0.4801 - val_loss: 1.5274 - val_accuracy: 0.4550\n",
      "Epoch 23/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.4857 - accuracy: 0.4817 - val_loss: 1.5235 - val_accuracy: 0.4588\n",
      "Epoch 24/30\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 1.4772 - accuracy: 0.4826 - val_loss: 1.5526 - val_accuracy: 0.4486\n",
      "Epoch 25/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.4690 - accuracy: 0.4870 - val_loss: 1.5284 - val_accuracy: 0.4545\n",
      "Epoch 26/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.4621 - accuracy: 0.4891 - val_loss: 1.5637 - val_accuracy: 0.4493\n",
      "Epoch 27/30\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 1.4575 - accuracy: 0.4900 - val_loss: 1.4868 - val_accuracy: 0.4736\n",
      "Epoch 28/30\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.4464 - accuracy: 0.4938 - val_loss: 1.5087 - val_accuracy: 0.4653\n",
      "Epoch 29/30\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 1.4379 - accuracy: 0.4988 - val_loss: 1.4819 - val_accuracy: 0.4749\n",
      "Epoch 30/30\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.4313 - accuracy: 0.4999 - val_loss: 1.4883 - val_accuracy: 0.4703\n",
      "\n",
      "Test accuracy: 47.0%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=False)\n",
    "\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Using 3-Layer CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "image_size = x_train.shape[1]\n",
    "# resize and normalize\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "input_shape = (image_size, image_size, 3)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "pool_size = 3\n",
    "filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Conv2D)         (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "hidden_layer (MaxPooling2D)  (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Flatten)      (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                32010     \n",
      "=================================================================\n",
      "Total params: 32,906\n",
      "Trainable params: 32,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size, \n",
    "                 activation='relu', \n",
    "                 kernel_initializer='he_uniform', \n",
    "                 padding='same', \n",
    "                 input_shape=input_shape,\n",
    "                 name='input_layer'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size,name='hidden_layer'))\n",
    "model.add(Flatten(name='hidden_layer2'))\n",
    "model.add(Dense(10, activation='softmax',name='output_layer'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 2.1054 - accuracy: 0.2499\n",
      "Epoch 2/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.9082 - accuracy: 0.3414\n",
      "Epoch 3/30\n",
      "196/196 [==============================] - 19s 99ms/step - loss: 1.8153 - accuracy: 0.3774\n",
      "Epoch 4/30\n",
      "196/196 [==============================] - 19s 99ms/step - loss: 1.7509 - accuracy: 0.3999\n",
      "Epoch 5/30\n",
      "196/196 [==============================] - 19s 98ms/step - loss: 1.7011 - accuracy: 0.4202\n",
      "Epoch 6/30\n",
      "196/196 [==============================] - 21s 106ms/step - loss: 1.6595 - accuracy: 0.4336\n",
      "Epoch 7/30\n",
      "196/196 [==============================] - 25s 128ms/step - loss: 1.6211 - accuracy: 0.4495\n",
      "Epoch 8/30\n",
      "196/196 [==============================] - 26s 134ms/step - loss: 1.5878 - accuracy: 0.4591\n",
      "Epoch 9/30\n",
      "196/196 [==============================] - 24s 124ms/step - loss: 1.5589 - accuracy: 0.4683\n",
      "Epoch 10/30\n",
      "196/196 [==============================] - 26s 131ms/step - loss: 1.5322 - accuracy: 0.4778\n",
      "Epoch 11/30\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 1.5073 - accuracy: 0.4858\n",
      "Epoch 12/30\n",
      "196/196 [==============================] - 22s 115ms/step - loss: 1.4846 - accuracy: 0.4955\n",
      "Epoch 13/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.4636 - accuracy: 0.5001\n",
      "Epoch 14/30\n",
      "196/196 [==============================] - 20s 100ms/step - loss: 1.4444 - accuracy: 0.5075\n",
      "Epoch 15/30\n",
      "196/196 [==============================] - 20s 100ms/step - loss: 1.4271 - accuracy: 0.5121\n",
      "Epoch 16/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.4103 - accuracy: 0.5189\n",
      "Epoch 17/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.3948 - accuracy: 0.5236\n",
      "Epoch 18/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.3809 - accuracy: 0.5289\n",
      "Epoch 19/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.3665 - accuracy: 0.5327\n",
      "Epoch 20/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.3542 - accuracy: 0.5370\n",
      "Epoch 21/30\n",
      "196/196 [==============================] - 20s 100ms/step - loss: 1.3427 - accuracy: 0.5407\n",
      "Epoch 22/30\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 1.3325 - accuracy: 0.5451\n",
      "Epoch 23/30\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 1.3220 - accuracy: 0.5474\n",
      "Epoch 24/30\n",
      "196/196 [==============================] - 21s 107ms/step - loss: 1.3108 - accuracy: 0.5513\n",
      "Epoch 25/30\n",
      "196/196 [==============================] - 24s 121ms/step - loss: 1.3028 - accuracy: 0.5556\n",
      "Epoch 26/30\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 1.2938 - accuracy: 0.5574\n",
      "Epoch 27/30\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 1.2858 - accuracy: 0.5610\n",
      "Epoch 28/30\n",
      "196/196 [==============================] - 21s 106ms/step - loss: 1.2782 - accuracy: 0.5626\n",
      "Epoch 29/30\n",
      "196/196 [==============================] - 21s 107ms/step - loss: 1.2705 - accuracy: 0.5663\n",
      "Epoch 30/30\n",
      " 42/196 [=====>........................] - ETA: 16s - loss: 1.2545 - accuracy: 0.5707"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **3. Performance**\n",
    "\n",
    "The MLP model was outperformed by the CNN model using the same epochs and layers. \n",
    "The MLP's accuracy of ~47% was lower compared to the CNN accuracy of ~60%.\n",
    "The MLP also used approximately ten times as much parameters at 855,050 compared to the CNN at 82,346.\n",
    "The CNN model was more parameter efficient and has higher accuracy and thus is more suitable to use for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
